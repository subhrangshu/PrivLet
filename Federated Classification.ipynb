{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e2cf2c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy \n",
    "import sklearn \n",
    "from sklearn import datasets\n",
    "import syft \n",
    "import diffprivlib\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,auc,average_precision_score,balanced_accuracy_score,brier_score_loss,classification_report,cohen_kappa_score,confusion_matrix,dcg_score,det_curve,f1_score,fbeta_score,hamming_loss,hinge_loss,jaccard_score,log_loss,matthews_corrcoef,multilabel_confusion_matrix,ndcg_score,precision_recall_curve,precision_recall_fscore_support,precision_score,recall_score,roc_auc_score,roc_curve,top_k_accuracy_score,zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0327baec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combined = pd.read_csv('Combined.csv')\n",
    "combinedDWT = pd.read_csv('Combined DWT.csv')\n",
    "combinedButterworth = pd.read_csv('Combined Butterworth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dafabd92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combined = combined.sample(frac=1).reset_index(drop=True)\n",
    "combinedDWT = combinedDWT.sample(frac=1).reset_index(drop=True)\n",
    "combinedButterworth = combinedButterworth.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "918c812e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb9342ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d1e970d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.24682</td>\n",
       "      <td>0.738531</td>\n",
       "      <td>0.24682</td>\n",
       "      <td>0.680729</td>\n",
       "      <td>0.751456</td>\n",
       "      <td>0.829387</td>\n",
       "      <td>0.830524</td>\n",
       "      <td>0.830317</td>\n",
       "      <td>0.830421</td>\n",
       "      <td>0.830421</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.145297</td>\n",
       "      <td>0.393289</td>\n",
       "      <td>0.145297</td>\n",
       "      <td>0.468519</td>\n",
       "      <td>0.618691</td>\n",
       "      <td>0.768487</td>\n",
       "      <td>0.77131</td>\n",
       "      <td>0.771026</td>\n",
       "      <td>0.771171</td>\n",
       "      <td>0.771171</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.12341</td>\n",
       "      <td>0.374755</td>\n",
       "      <td>0.12341</td>\n",
       "      <td>0.474825</td>\n",
       "      <td>0.642851</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>0.772777</td>\n",
       "      <td>0.772491</td>\n",
       "      <td>0.772631</td>\n",
       "      <td>0.772631</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.490275</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.485514</td>\n",
       "      <td>0.590298</td>\n",
       "      <td>0.753706</td>\n",
       "      <td>0.765868</td>\n",
       "      <td>0.76559</td>\n",
       "      <td>0.765752</td>\n",
       "      <td>0.765752</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>60.486689</td>\n",
       "      <td>0.200771</td>\n",
       "      <td>0.136941</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.10925</td>\n",
       "      <td>0.106429</td>\n",
       "      <td>0.100889</td>\n",
       "      <td>0.10544</td>\n",
       "      <td>0.117998</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.75318</td>\n",
       "      <td>0.704064</td>\n",
       "      <td>0.65381</td>\n",
       "      <td>0.666081</td>\n",
       "      <td>0.685796</td>\n",
       "      <td>0.751491</td>\n",
       "      <td>0.749388</td>\n",
       "      <td>0.74925</td>\n",
       "      <td>0.749354</td>\n",
       "      <td>0.749285</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.396145</td>\n",
       "      <td>0.426279</td>\n",
       "      <td>0.426382</td>\n",
       "      <td>0.575154</td>\n",
       "      <td>0.512715</td>\n",
       "      <td>0.548683</td>\n",
       "      <td>0.540137</td>\n",
       "      <td>0.539632</td>\n",
       "      <td>0.53967</td>\n",
       "      <td>0.539575</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.37659</td>\n",
       "      <td>0.433052</td>\n",
       "      <td>0.425153</td>\n",
       "      <td>0.574578</td>\n",
       "      <td>0.519404</td>\n",
       "      <td>0.626969</td>\n",
       "      <td>0.616819</td>\n",
       "      <td>0.616153</td>\n",
       "      <td>0.616556</td>\n",
       "      <td>0.616267</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.478144</td>\n",
       "      <td>0.454594</td>\n",
       "      <td>0.583332</td>\n",
       "      <td>0.513522</td>\n",
       "      <td>0.538028</td>\n",
       "      <td>0.53405</td>\n",
       "      <td>0.533818</td>\n",
       "      <td>0.53384</td>\n",
       "      <td>0.533794</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.117665</td>\n",
       "      <td>0.143671</td>\n",
       "      <td>0.162499</td>\n",
       "      <td>0.211548</td>\n",
       "      <td>0.238757</td>\n",
       "      <td>0.245574</td>\n",
       "      <td>0.319015</td>\n",
       "      <td>0.317679</td>\n",
       "      <td>0.292083</td>\n",
       "      <td>0.264385</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.00131</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0               1e-05    0.0001     0.001      0.01       0.1         1  \\\n",
       "Metrics                                                                   \n",
       "Accuracy      0.24682  0.738531   0.24682  0.680729  0.751456  0.829387   \n",
       "FBeta        0.145297  0.393289  0.145297  0.468519  0.618691  0.768487   \n",
       "Precision     0.12341  0.374755   0.12341  0.474825  0.642851  0.773008   \n",
       "Recall            0.5  0.490275       0.5  0.485514  0.590298  0.753706   \n",
       "Train Time  60.486689  0.200771  0.136941  0.111977   0.10925  0.106429   \n",
       "Test Time    0.002459     0.003  0.003397  0.003091  0.002464  0.002837   \n",
       "Accuracy      0.75318  0.704064   0.65381  0.666081  0.685796  0.751491   \n",
       "FBeta        0.396145  0.426279  0.426382  0.575154  0.512715  0.548683   \n",
       "Precision     0.37659  0.433052  0.425153  0.574578  0.519404  0.626969   \n",
       "Recall            0.5  0.478144  0.454594  0.583332  0.513522  0.538028   \n",
       "Train Time   0.117665  0.143671  0.162499  0.211548  0.238757  0.245574   \n",
       "Test Time     0.00131   0.00141  0.001485  0.001936  0.001225  0.001234   \n",
       "\n",
       "0                 10       100      1000     10000           Algorithm  \\\n",
       "Metrics                                                                  \n",
       "Accuracy    0.830524  0.830317  0.830421  0.830421          GaussianNB   \n",
       "FBeta        0.77131  0.771026  0.771171  0.771171          GaussianNB   \n",
       "Precision   0.772777  0.772491  0.772631  0.772631          GaussianNB   \n",
       "Recall      0.765868   0.76559  0.765752  0.765752          GaussianNB   \n",
       "Train Time  0.100889   0.10544  0.117998  0.106398          GaussianNB   \n",
       "Test Time   0.002372  0.002916  0.002707  0.004086          GaussianNB   \n",
       "Accuracy    0.749388   0.74925  0.749354  0.749285  LogisticRegression   \n",
       "FBeta       0.540137  0.539632   0.53967  0.539575  LogisticRegression   \n",
       "Precision   0.616819  0.616153  0.616556  0.616267  LogisticRegression   \n",
       "Recall       0.53405  0.533818   0.53384  0.533794  LogisticRegression   \n",
       "Train Time  0.319015  0.317679  0.292083  0.264385  LogisticRegression   \n",
       "Test Time   0.001334  0.001426  0.001248  0.001372  LogisticRegression   \n",
       "\n",
       "0          Data Type  \n",
       "Metrics               \n",
       "Accuracy         Raw  \n",
       "FBeta            Raw  \n",
       "Precision        Raw  \n",
       "Recall           Raw  \n",
       "Train Time       Raw  \n",
       "Test Time        Raw  \n",
       "Accuracy         Raw  \n",
       "FBeta            Raw  \n",
       "Precision        Raw  \n",
       "Recall           Raw  \n",
       "Train Time       Raw  \n",
       "Test Time        Raw  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = combined[['Ax','Ay','Az','Gx','Gy','Gz']]\n",
    "labels = combined[['Diagnosis']]\n",
    "\n",
    "def sweep(eps=[0.00001, 0.001, 0.01, 10, 1000, 10000],modelname='GNB'):\n",
    "    data_train, data_test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels,random_state=100)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    fbeta = []\n",
    "    recall = []\n",
    "    roc_auc = []\n",
    "    brier_loss = []\n",
    "    train_time = []\n",
    "    test_time = []\n",
    "    epsilon = []\n",
    "    for i in range(len(eps)):\n",
    "        model = ''\n",
    "        if modelname=='GNB':\n",
    "            model = diffprivlib.models.GaussianNB(epsilon=eps[i])\n",
    "        elif modelname == 'LRG':\n",
    "            model = diffprivlib.models.LogisticRegression(epsilon=eps[i])\n",
    "        elif modelname == 'RFC':\n",
    "            model = diffprivlib.models.RandomForestClassifier(random_state=1,epsilon=eps[i])\n",
    "        elif modelname == 'DTC':\n",
    "            model = diffprivlib.models.DecisionTreeClassifier(random_state=1,epsilon=eps[i])\n",
    "        else:\n",
    "            print('Model name not correct')\n",
    "            return None\n",
    "\n",
    "        a = time.time()\n",
    "        model.fit(data_train, labels_train)\n",
    "        b = time.time()\n",
    "        c = time.time()\n",
    "        pred = model.predict(data_test)\n",
    "        d = time.time()\n",
    "        #pred = pd.Categorical(pred).codes\n",
    "        #print('Pred:')\n",
    "        #print(pred)\n",
    "        #labels_test = pd.Categorical(labels_test['Diagnosis']).codes\n",
    "        #print('Label:')\n",
    "        #print(labels_test)\n",
    "        train_time.append(b-a)\n",
    "        test_time.append(d-c)\n",
    "        epsilon.append(str(eps[i]))\n",
    "        accuracy.append(accuracy_score(labels_test, pred))\n",
    "        fbeta.append(fbeta_score(labels_test, pred, average='macro', beta=0.5))\n",
    "        precision.append(precision_score(labels_test, pred, average='macro'))\n",
    "        recall.append(recall_score(labels_test, pred, average='macro'))\n",
    "        #roc_auc.append(roc_auc_score(labels_test, pred))\n",
    "        #brier_loss.append(brier_score_loss(labels_test, pred))\n",
    "    values = [epsilon,accuracy,fbeta,precision,recall,train_time,test_time]\n",
    "    \"\"\"values = {\n",
    "        'Epsilon': epsilon,\n",
    "        #'Model': 'GaussianNB',\n",
    "        'Accuracy': accuracy,\n",
    "        'FBeta': fbeta,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        #'ROC AOC': roc_auc,\n",
    "        #'Brier Loss': brier_loss\n",
    "    }\"\"\"\n",
    "    return values\n",
    "\n",
    "eps=[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000] # Try changing these values to see how the accuracy plot changes!\n",
    "\n",
    "metrics = sweep(eps,'GNB')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'GaussianNB'\n",
    "gnb = df\n",
    "\n",
    "metrics = sweep(eps,'LRG')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'LogisticRegression'\n",
    "lrg = df\n",
    "\n",
    "\"\"\"metrics = sweep(eps,'RFC')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'Random Forest'\n",
    "rfc = df\n",
    "\n",
    "metrics = sweep(eps,'DTC')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'Decision Tree'\n",
    "dtc = df\"\"\"\n",
    "\n",
    "raw = pd.concat([gnb,lrg],axis=0)\n",
    "raw['Data Type'] = 'Raw'\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79509d4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:413: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:413: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.247165</td>\n",
       "      <td>0.752835</td>\n",
       "      <td>0.725399</td>\n",
       "      <td>0.786613</td>\n",
       "      <td>0.829973</td>\n",
       "      <td>0.88388</td>\n",
       "      <td>0.887085</td>\n",
       "      <td>0.887602</td>\n",
       "      <td>0.887568</td>\n",
       "      <td>0.887568</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.145488</td>\n",
       "      <td>0.395993</td>\n",
       "      <td>0.39058</td>\n",
       "      <td>0.728338</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.847419</td>\n",
       "      <td>0.852113</td>\n",
       "      <td>0.85285</td>\n",
       "      <td>0.852805</td>\n",
       "      <td>0.852805</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.123583</td>\n",
       "      <td>0.376417</td>\n",
       "      <td>0.372931</td>\n",
       "      <td>0.724556</td>\n",
       "      <td>0.775871</td>\n",
       "      <td>0.855873</td>\n",
       "      <td>0.860729</td>\n",
       "      <td>0.86145</td>\n",
       "      <td>0.861415</td>\n",
       "      <td>0.861415</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.481778</td>\n",
       "      <td>0.762269</td>\n",
       "      <td>0.82769</td>\n",
       "      <td>0.821062</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.826016</td>\n",
       "      <td>0.825946</td>\n",
       "      <td>0.825946</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>79.148934</td>\n",
       "      <td>6.674312</td>\n",
       "      <td>0.155501</td>\n",
       "      <td>0.122466</td>\n",
       "      <td>0.101879</td>\n",
       "      <td>0.103122</td>\n",
       "      <td>0.108585</td>\n",
       "      <td>0.101325</td>\n",
       "      <td>0.101835</td>\n",
       "      <td>0.101636</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.247165</td>\n",
       "      <td>0.247165</td>\n",
       "      <td>0.641126</td>\n",
       "      <td>0.839693</td>\n",
       "      <td>0.816427</td>\n",
       "      <td>0.864095</td>\n",
       "      <td>0.872781</td>\n",
       "      <td>0.872368</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.145488</td>\n",
       "      <td>0.145488</td>\n",
       "      <td>0.587626</td>\n",
       "      <td>0.791812</td>\n",
       "      <td>0.743486</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.850023</td>\n",
       "      <td>0.850024</td>\n",
       "      <td>0.847464</td>\n",
       "      <td>0.847464</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.123583</td>\n",
       "      <td>0.123583</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>0.90572</td>\n",
       "      <td>0.768231</td>\n",
       "      <td>0.910435</td>\n",
       "      <td>0.915081</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.916677</td>\n",
       "      <td>0.916677</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.618763</td>\n",
       "      <td>0.677394</td>\n",
       "      <td>0.695053</td>\n",
       "      <td>0.72971</td>\n",
       "      <td>0.747515</td>\n",
       "      <td>0.745554</td>\n",
       "      <td>0.742277</td>\n",
       "      <td>0.742277</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.126789</td>\n",
       "      <td>0.124429</td>\n",
       "      <td>0.135993</td>\n",
       "      <td>0.220526</td>\n",
       "      <td>0.331587</td>\n",
       "      <td>0.332329</td>\n",
       "      <td>0.441089</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.506005</td>\n",
       "      <td>0.559494</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0               1e-05    0.0001     0.001      0.01       0.1         1  \\\n",
       "Metrics                                                                   \n",
       "Accuracy     0.247165  0.752835  0.725399  0.786613  0.829973   0.88388   \n",
       "FBeta        0.145488  0.395993   0.39058  0.728338  0.780897  0.847419   \n",
       "Precision    0.123583  0.376417  0.372931  0.724556  0.775871  0.855873   \n",
       "Recall            0.5       0.5  0.481778  0.762269   0.82769  0.821062   \n",
       "Train Time  79.148934  6.674312  0.155501  0.122466  0.101879  0.103122   \n",
       "Test Time    0.002415  0.002356  0.002404   0.00249  0.002446  0.003006   \n",
       "Accuracy     0.247165  0.247165  0.641126  0.839693  0.816427  0.864095   \n",
       "FBeta        0.145488  0.145488  0.587626  0.791812  0.743486  0.836139   \n",
       "Precision    0.123583  0.123583  0.592415   0.90572  0.768231  0.910435   \n",
       "Recall            0.5       0.5  0.618763  0.677394  0.695053   0.72971   \n",
       "Train Time   0.126789  0.124429  0.135993  0.220526  0.331587  0.332329   \n",
       "Test Time    0.001182  0.001331  0.001253   0.00171  0.001631  0.001233   \n",
       "\n",
       "0                 10       100      1000     10000           Algorithm  \\\n",
       "Metrics                                                                  \n",
       "Accuracy    0.887085  0.887602  0.887568  0.887568          GaussianNB   \n",
       "FBeta       0.852113   0.85285  0.852805  0.852805          GaussianNB   \n",
       "Precision   0.860729   0.86145  0.861415  0.861415          GaussianNB   \n",
       "Recall      0.825251  0.826016  0.825946  0.825946          GaussianNB   \n",
       "Train Time  0.108585  0.101325  0.101835  0.101636          GaussianNB   \n",
       "Test Time   0.002764  0.002624  0.002413  0.002393          GaussianNB   \n",
       "Accuracy    0.872781  0.872368  0.870748  0.870748  LogisticRegression   \n",
       "FBeta       0.850023  0.850024  0.847464  0.847464  LogisticRegression   \n",
       "Precision   0.915081  0.917614  0.916677  0.916677  LogisticRegression   \n",
       "Recall      0.747515  0.745554  0.742277  0.742277  LogisticRegression   \n",
       "Train Time  0.441089  0.494465  0.506005  0.559494  LogisticRegression   \n",
       "Test Time   0.001169  0.001334   0.00124  0.001383  LogisticRegression   \n",
       "\n",
       "0          Data Type  \n",
       "Metrics               \n",
       "Accuracy         DWT  \n",
       "FBeta            DWT  \n",
       "Precision        DWT  \n",
       "Recall           DWT  \n",
       "Train Time       DWT  \n",
       "Test Time        DWT  \n",
       "Accuracy         DWT  \n",
       "FBeta            DWT  \n",
       "Precision        DWT  \n",
       "Recall           DWT  \n",
       "Train Time       DWT  \n",
       "Test Time        DWT  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = combinedDWT[['Ax','Ay','Az','Gx','Gy','Gz']]\n",
    "labels = combinedDWT[['Diagnosis']]\n",
    "\n",
    "def sweep(eps=[0.00001, 0.001, 0.01, 10, 1000, 10000],modelname='GNB'):\n",
    "    data_train, data_test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels,random_state=100)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    fbeta = []\n",
    "    recall = []\n",
    "    roc_auc = []\n",
    "    brier_loss = []\n",
    "    epsilon = []\n",
    "    train_time = []\n",
    "    test_time = []\n",
    "    for i in range(len(eps)):\n",
    "        model = ''\n",
    "        if modelname=='GNB':\n",
    "            model = diffprivlib.models.GaussianNB(epsilon=eps[i])\n",
    "        elif modelname == 'LRG':\n",
    "            model = diffprivlib.models.LogisticRegression(epsilon=eps[i])\n",
    "        elif modelname == 'RFC':\n",
    "            model = diffprivlib.models.RandomForestClassifier(n_estimators=100, random_state=0,epsilon=eps[i])\n",
    "        elif modelname == 'DTC':\n",
    "            model = diffprivlib.models.DecisionTreeClassifier(random_state=1,epsilon=eps[i])\n",
    "        else:\n",
    "            print('Model name not correct')\n",
    "            return None\n",
    "\n",
    "        a = time.time()\n",
    "        model.fit(data_train, labels_train)\n",
    "        b = time.time()\n",
    "        c = time.time()\n",
    "        pred = model.predict(data_test)\n",
    "        d = time.time()\n",
    "        #pred = pd.Categorical(pred).codes\n",
    "        #print('Pred:')\n",
    "        #print(pred)\n",
    "        #labels_test = pd.Categorical(labels_test['Diagnosis']).codes\n",
    "        #print('Label:')\n",
    "        #print(labels_test)\n",
    "        train_time.append(b-a)\n",
    "        test_time.append(d-c)\n",
    "        epsilon.append(str(eps[i]))\n",
    "        accuracy.append(accuracy_score(labels_test, pred))\n",
    "        fbeta.append(fbeta_score(labels_test, pred, average='macro', beta=0.5))\n",
    "        precision.append(precision_score(labels_test, pred, average='macro'))\n",
    "        recall.append(recall_score(labels_test, pred, average='macro'))\n",
    "        #roc_auc.append(roc_auc_score(labels_test, pred))\n",
    "        #brier_loss.append(brier_score_loss(labels_test, pred))\n",
    "    values = [epsilon,accuracy,fbeta,precision,recall,train_time,test_time]\n",
    "    \"\"\"values = {\n",
    "        'Epsilon': epsilon,\n",
    "        #'Model': 'GaussianNB',\n",
    "        'Accuracy': accuracy,\n",
    "        'FBeta': fbeta,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        #'ROC AOC': roc_auc,\n",
    "        #'Brier Loss': brier_loss\n",
    "    }\"\"\"\n",
    "    return values\n",
    "\n",
    "eps=[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000] # Try changing these values to see how the accuracy plot changes!\n",
    "\n",
    "metrics = sweep(eps,'GNB')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'GaussianNB'\n",
    "gnb = df\n",
    "\n",
    "metrics = sweep(eps,'LRG')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'LogisticRegression'\n",
    "lrg = df\n",
    "\n",
    "\"\"\"metrics = sweep(eps,'RFC')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'Random Forest'\n",
    "rfc = df\n",
    "\n",
    "metrics = sweep(eps,'DTC')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'Decision Tree'\n",
    "dtc = df\"\"\"\n",
    "\n",
    "dwt = pd.concat([gnb,lrg],axis=0)\n",
    "dwt['Data Type'] = 'DWT'\n",
    "dwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b766a73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/subhrangshu/anaconda3/envs/Federated-Learning/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:233: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.739737</td>\n",
       "      <td>0.459725</td>\n",
       "      <td>0.338124</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.811533</td>\n",
       "      <td>0.822597</td>\n",
       "      <td>0.821804</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.821149</td>\n",
       "      <td>0.821149</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.436029</td>\n",
       "      <td>0.493494</td>\n",
       "      <td>0.373202</td>\n",
       "      <td>0.66752</td>\n",
       "      <td>0.743675</td>\n",
       "      <td>0.758238</td>\n",
       "      <td>0.757287</td>\n",
       "      <td>0.756248</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.499436</td>\n",
       "      <td>0.567409</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>0.748772</td>\n",
       "      <td>0.767386</td>\n",
       "      <td>0.765679</td>\n",
       "      <td>0.764972</td>\n",
       "      <td>0.764913</td>\n",
       "      <td>0.764913</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.499931</td>\n",
       "      <td>0.576663</td>\n",
       "      <td>0.470136</td>\n",
       "      <td>0.64067</td>\n",
       "      <td>0.727792</td>\n",
       "      <td>0.73274</td>\n",
       "      <td>0.733419</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.731684</td>\n",
       "      <td>0.731684</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.880714</td>\n",
       "      <td>1.666841</td>\n",
       "      <td>0.249369</td>\n",
       "      <td>0.102694</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>0.10829</td>\n",
       "      <td>0.130749</td>\n",
       "      <td>0.09811</td>\n",
       "      <td>0.126721</td>\n",
       "      <td>0.120502</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.248509</td>\n",
       "      <td>0.751491</td>\n",
       "      <td>0.710992</td>\n",
       "      <td>0.754834</td>\n",
       "      <td>0.809499</td>\n",
       "      <td>0.83859</td>\n",
       "      <td>0.840416</td>\n",
       "      <td>0.840554</td>\n",
       "      <td>0.840658</td>\n",
       "      <td>0.840623</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.146233</td>\n",
       "      <td>0.395397</td>\n",
       "      <td>0.51077</td>\n",
       "      <td>0.670932</td>\n",
       "      <td>0.721581</td>\n",
       "      <td>0.784963</td>\n",
       "      <td>0.789205</td>\n",
       "      <td>0.789522</td>\n",
       "      <td>0.789724</td>\n",
       "      <td>0.78966</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.124255</td>\n",
       "      <td>0.375745</td>\n",
       "      <td>0.531376</td>\n",
       "      <td>0.671204</td>\n",
       "      <td>0.82868</td>\n",
       "      <td>0.842859</td>\n",
       "      <td>0.853304</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.515617</td>\n",
       "      <td>0.669877</td>\n",
       "      <td>0.63319</td>\n",
       "      <td>0.700725</td>\n",
       "      <td>0.699898</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>0.700059</td>\n",
       "      <td>0.699989</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.136425</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.181493</td>\n",
       "      <td>0.217716</td>\n",
       "      <td>0.35796</td>\n",
       "      <td>0.38343</td>\n",
       "      <td>0.398101</td>\n",
       "      <td>0.395138</td>\n",
       "      <td>0.406332</td>\n",
       "      <td>0.416245</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.00138</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0              1e-05    0.0001     0.001      0.01       0.1         1  \\\n",
       "Metrics                                                                  \n",
       "Accuracy    0.739737  0.459725  0.338124  0.767932  0.811533  0.822597   \n",
       "FBeta       0.436029  0.493494  0.373202   0.66752  0.743675  0.758238   \n",
       "Precision   0.499436  0.567409  0.467763  0.680959  0.748772  0.767386   \n",
       "Recall      0.499931  0.576663  0.470136   0.64067  0.727792   0.73274   \n",
       "Train Time  0.880714  1.666841  0.249369  0.102694  0.098618   0.10829   \n",
       "Test Time    0.00246  0.002596  0.005092  0.002375  0.002362  0.003235   \n",
       "Accuracy    0.248509  0.751491  0.710992  0.754834  0.809499   0.83859   \n",
       "FBeta       0.146233  0.395397   0.51077  0.670932  0.721581  0.784963   \n",
       "Precision   0.124255  0.375745  0.531376  0.671204   0.82868  0.842859   \n",
       "Recall           0.5       0.5  0.515617  0.669877   0.63319  0.700725   \n",
       "Train Time  0.136425  0.141401  0.181493  0.217716   0.35796   0.38343   \n",
       "Test Time   0.001442  0.001812  0.001422  0.002025   0.00138  0.001363   \n",
       "\n",
       "0                 10       100      1000     10000           Algorithm  \\\n",
       "Metrics                                                                  \n",
       "Accuracy    0.821804  0.821184  0.821149  0.821149          GaussianNB   \n",
       "FBeta       0.757287  0.756248    0.7562    0.7562          GaussianNB   \n",
       "Precision   0.765679  0.764972  0.764913  0.764913          GaussianNB   \n",
       "Recall      0.733419  0.731707  0.731684  0.731684          GaussianNB   \n",
       "Train Time  0.130749   0.09811  0.126721  0.120502          GaussianNB   \n",
       "Test Time   0.002405  0.002377  0.002909  0.002815          GaussianNB   \n",
       "Accuracy    0.840416  0.840554  0.840658  0.840623  LogisticRegression   \n",
       "FBeta       0.789205  0.789522  0.789724   0.78966  LogisticRegression   \n",
       "Precision   0.853304  0.854004  0.854202  0.854167  LogisticRegression   \n",
       "Recall      0.699898  0.699897  0.700059  0.699989  LogisticRegression   \n",
       "Train Time  0.398101  0.395138  0.406332  0.416245  LogisticRegression   \n",
       "Test Time   0.001339  0.001411  0.002447   0.00182  LogisticRegression   \n",
       "\n",
       "0          Data Type  \n",
       "Metrics               \n",
       "Accuracy          BW  \n",
       "FBeta             BW  \n",
       "Precision         BW  \n",
       "Recall            BW  \n",
       "Train Time        BW  \n",
       "Test Time         BW  \n",
       "Accuracy          BW  \n",
       "FBeta             BW  \n",
       "Precision         BW  \n",
       "Recall            BW  \n",
       "Train Time        BW  \n",
       "Test Time         BW  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = combinedButterworth[['Ax','Ay','Az','Gx','Gy','Gz']]\n",
    "labels = combinedButterworth[['Diagnosis']]\n",
    "\n",
    "def sweep(eps=[0.00001, 0.001, 0.01, 10, 1000, 10000],modelname='GNB'):\n",
    "    data_train, data_test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels,random_state=100)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    fbeta = []\n",
    "    recall = []\n",
    "    roc_auc = []\n",
    "    brier_loss = []\n",
    "    epsilon = []\n",
    "    train_time = []\n",
    "    test_time = []\n",
    "    for i in range(len(eps)):\n",
    "        model = ''\n",
    "        if modelname=='GNB':\n",
    "            model = diffprivlib.models.GaussianNB(epsilon=eps[i])\n",
    "        elif modelname == 'LRG':\n",
    "            model = diffprivlib.models.LogisticRegression(epsilon=eps[i])\n",
    "        elif modelname == 'RFC':\n",
    "            model = diffprivlib.models.RandomForestClassifier(n_estimators=100, random_state=0,epsilon=eps[i])\n",
    "        elif modelname == 'DTC':\n",
    "            model = diffprivlib.models.DecisionTreeClassifier(random_state=1,epsilon=eps[i])\n",
    "        else:\n",
    "            print('Model name not correct')\n",
    "            return None\n",
    "        a = time.time()\n",
    "        model.fit(data_train, labels_train)\n",
    "        b = time.time()\n",
    "        c = time.time()\n",
    "        pred = model.predict(data_test)\n",
    "        d = time.time()\n",
    "        #pred = pd.Categorical(pred).codes\n",
    "        #print('Pred:')\n",
    "        #print(pred)\n",
    "        #labels_test = pd.Categorical(labels_test['Diagnosis']).codes\n",
    "        #print('Label:')\n",
    "        #print(labels_test)\n",
    "        epsilon.append(str(eps[i]))\n",
    "        accuracy.append(accuracy_score(labels_test, pred))\n",
    "        fbeta.append(fbeta_score(labels_test, pred, average='macro', beta=0.5))\n",
    "        precision.append(precision_score(labels_test, pred, average='macro'))\n",
    "        recall.append(recall_score(labels_test, pred, average='macro'))\n",
    "        train_time.append(b-a)\n",
    "        test_time.append(d-c)\n",
    "        #roc_auc.append(roc_auc_score(labels_test, pred))\n",
    "        #brier_loss.append(brier_score_loss(labels_test, pred))\n",
    "    values = [epsilon,accuracy,fbeta,precision,recall,train_time,test_time]\n",
    "    \"\"\"values = {\n",
    "        'Epsilon': epsilon,\n",
    "        #'Model': 'GaussianNB',\n",
    "        'Accuracy': accuracy,\n",
    "        'FBeta': fbeta,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        #'ROC AOC': roc_auc,\n",
    "        #'Brier Loss': brier_loss\n",
    "    }\"\"\"\n",
    "    return values\n",
    "\n",
    "eps=[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000] # Try changing these values to see how the accuracy plot changes!\n",
    "\n",
    "metrics = sweep(eps,'GNB')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'GaussianNB'\n",
    "gnb = df\n",
    "\n",
    "metrics = sweep(eps,'LRG')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'LogisticRegression'\n",
    "lrg = df\n",
    "\n",
    "\"\"\"metrics = sweep(eps,'RFC')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'Random Forest'\n",
    "rfc = df\n",
    "\n",
    "metrics = sweep(eps,'DTC')\n",
    "df = pd.DataFrame(metrics)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['Metrics'] = ['Accuracy','FBeta','Precision','Recall','Train Time','Test Time']\n",
    "df = df.set_index('Metrics')\n",
    "df['Algorithm'] = 'Decision Tree'\n",
    "dtc = df\"\"\"\n",
    "\n",
    "bw = pd.concat([gnb,lrg],axis=0)\n",
    "bw['Data Type'] = 'BW'\n",
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e3f3e1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.24682</td>\n",
       "      <td>0.738531</td>\n",
       "      <td>0.24682</td>\n",
       "      <td>0.680729</td>\n",
       "      <td>0.751456</td>\n",
       "      <td>0.829387</td>\n",
       "      <td>0.830524</td>\n",
       "      <td>0.830317</td>\n",
       "      <td>0.830421</td>\n",
       "      <td>0.830421</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.145297</td>\n",
       "      <td>0.393289</td>\n",
       "      <td>0.145297</td>\n",
       "      <td>0.468519</td>\n",
       "      <td>0.618691</td>\n",
       "      <td>0.768487</td>\n",
       "      <td>0.77131</td>\n",
       "      <td>0.771026</td>\n",
       "      <td>0.771171</td>\n",
       "      <td>0.771171</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.12341</td>\n",
       "      <td>0.374755</td>\n",
       "      <td>0.12341</td>\n",
       "      <td>0.474825</td>\n",
       "      <td>0.642851</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>0.772777</td>\n",
       "      <td>0.772491</td>\n",
       "      <td>0.772631</td>\n",
       "      <td>0.772631</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.490275</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.485514</td>\n",
       "      <td>0.590298</td>\n",
       "      <td>0.753706</td>\n",
       "      <td>0.765868</td>\n",
       "      <td>0.76559</td>\n",
       "      <td>0.765752</td>\n",
       "      <td>0.765752</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>60.486689</td>\n",
       "      <td>0.200771</td>\n",
       "      <td>0.136941</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.10925</td>\n",
       "      <td>0.106429</td>\n",
       "      <td>0.100889</td>\n",
       "      <td>0.10544</td>\n",
       "      <td>0.117998</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.75318</td>\n",
       "      <td>0.704064</td>\n",
       "      <td>0.65381</td>\n",
       "      <td>0.666081</td>\n",
       "      <td>0.685796</td>\n",
       "      <td>0.751491</td>\n",
       "      <td>0.749388</td>\n",
       "      <td>0.74925</td>\n",
       "      <td>0.749354</td>\n",
       "      <td>0.749285</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.396145</td>\n",
       "      <td>0.426279</td>\n",
       "      <td>0.426382</td>\n",
       "      <td>0.575154</td>\n",
       "      <td>0.512715</td>\n",
       "      <td>0.548683</td>\n",
       "      <td>0.540137</td>\n",
       "      <td>0.539632</td>\n",
       "      <td>0.53967</td>\n",
       "      <td>0.539575</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.37659</td>\n",
       "      <td>0.433052</td>\n",
       "      <td>0.425153</td>\n",
       "      <td>0.574578</td>\n",
       "      <td>0.519404</td>\n",
       "      <td>0.626969</td>\n",
       "      <td>0.616819</td>\n",
       "      <td>0.616153</td>\n",
       "      <td>0.616556</td>\n",
       "      <td>0.616267</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.478144</td>\n",
       "      <td>0.454594</td>\n",
       "      <td>0.583332</td>\n",
       "      <td>0.513522</td>\n",
       "      <td>0.538028</td>\n",
       "      <td>0.53405</td>\n",
       "      <td>0.533818</td>\n",
       "      <td>0.53384</td>\n",
       "      <td>0.533794</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.117665</td>\n",
       "      <td>0.143671</td>\n",
       "      <td>0.162499</td>\n",
       "      <td>0.211548</td>\n",
       "      <td>0.238757</td>\n",
       "      <td>0.245574</td>\n",
       "      <td>0.319015</td>\n",
       "      <td>0.317679</td>\n",
       "      <td>0.292083</td>\n",
       "      <td>0.264385</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.00131</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.247165</td>\n",
       "      <td>0.752835</td>\n",
       "      <td>0.725399</td>\n",
       "      <td>0.786613</td>\n",
       "      <td>0.829973</td>\n",
       "      <td>0.88388</td>\n",
       "      <td>0.887085</td>\n",
       "      <td>0.887602</td>\n",
       "      <td>0.887568</td>\n",
       "      <td>0.887568</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.145488</td>\n",
       "      <td>0.395993</td>\n",
       "      <td>0.39058</td>\n",
       "      <td>0.728338</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.847419</td>\n",
       "      <td>0.852113</td>\n",
       "      <td>0.85285</td>\n",
       "      <td>0.852805</td>\n",
       "      <td>0.852805</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.123583</td>\n",
       "      <td>0.376417</td>\n",
       "      <td>0.372931</td>\n",
       "      <td>0.724556</td>\n",
       "      <td>0.775871</td>\n",
       "      <td>0.855873</td>\n",
       "      <td>0.860729</td>\n",
       "      <td>0.86145</td>\n",
       "      <td>0.861415</td>\n",
       "      <td>0.861415</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.481778</td>\n",
       "      <td>0.762269</td>\n",
       "      <td>0.82769</td>\n",
       "      <td>0.821062</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.826016</td>\n",
       "      <td>0.825946</td>\n",
       "      <td>0.825946</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>79.148934</td>\n",
       "      <td>6.674312</td>\n",
       "      <td>0.155501</td>\n",
       "      <td>0.122466</td>\n",
       "      <td>0.101879</td>\n",
       "      <td>0.103122</td>\n",
       "      <td>0.108585</td>\n",
       "      <td>0.101325</td>\n",
       "      <td>0.101835</td>\n",
       "      <td>0.101636</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.247165</td>\n",
       "      <td>0.247165</td>\n",
       "      <td>0.641126</td>\n",
       "      <td>0.839693</td>\n",
       "      <td>0.816427</td>\n",
       "      <td>0.864095</td>\n",
       "      <td>0.872781</td>\n",
       "      <td>0.872368</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.145488</td>\n",
       "      <td>0.145488</td>\n",
       "      <td>0.587626</td>\n",
       "      <td>0.791812</td>\n",
       "      <td>0.743486</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.850023</td>\n",
       "      <td>0.850024</td>\n",
       "      <td>0.847464</td>\n",
       "      <td>0.847464</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.123583</td>\n",
       "      <td>0.123583</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>0.90572</td>\n",
       "      <td>0.768231</td>\n",
       "      <td>0.910435</td>\n",
       "      <td>0.915081</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.916677</td>\n",
       "      <td>0.916677</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.618763</td>\n",
       "      <td>0.677394</td>\n",
       "      <td>0.695053</td>\n",
       "      <td>0.72971</td>\n",
       "      <td>0.747515</td>\n",
       "      <td>0.745554</td>\n",
       "      <td>0.742277</td>\n",
       "      <td>0.742277</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.126789</td>\n",
       "      <td>0.124429</td>\n",
       "      <td>0.135993</td>\n",
       "      <td>0.220526</td>\n",
       "      <td>0.331587</td>\n",
       "      <td>0.332329</td>\n",
       "      <td>0.441089</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.506005</td>\n",
       "      <td>0.559494</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>DWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.739737</td>\n",
       "      <td>0.459725</td>\n",
       "      <td>0.338124</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.811533</td>\n",
       "      <td>0.822597</td>\n",
       "      <td>0.821804</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.821149</td>\n",
       "      <td>0.821149</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.436029</td>\n",
       "      <td>0.493494</td>\n",
       "      <td>0.373202</td>\n",
       "      <td>0.66752</td>\n",
       "      <td>0.743675</td>\n",
       "      <td>0.758238</td>\n",
       "      <td>0.757287</td>\n",
       "      <td>0.756248</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.499436</td>\n",
       "      <td>0.567409</td>\n",
       "      <td>0.467763</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>0.748772</td>\n",
       "      <td>0.767386</td>\n",
       "      <td>0.765679</td>\n",
       "      <td>0.764972</td>\n",
       "      <td>0.764913</td>\n",
       "      <td>0.764913</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.499931</td>\n",
       "      <td>0.576663</td>\n",
       "      <td>0.470136</td>\n",
       "      <td>0.64067</td>\n",
       "      <td>0.727792</td>\n",
       "      <td>0.73274</td>\n",
       "      <td>0.733419</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.731684</td>\n",
       "      <td>0.731684</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.880714</td>\n",
       "      <td>1.666841</td>\n",
       "      <td>0.249369</td>\n",
       "      <td>0.102694</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>0.10829</td>\n",
       "      <td>0.130749</td>\n",
       "      <td>0.09811</td>\n",
       "      <td>0.126721</td>\n",
       "      <td>0.120502</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.248509</td>\n",
       "      <td>0.751491</td>\n",
       "      <td>0.710992</td>\n",
       "      <td>0.754834</td>\n",
       "      <td>0.809499</td>\n",
       "      <td>0.83859</td>\n",
       "      <td>0.840416</td>\n",
       "      <td>0.840554</td>\n",
       "      <td>0.840658</td>\n",
       "      <td>0.840623</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBeta</th>\n",
       "      <td>0.146233</td>\n",
       "      <td>0.395397</td>\n",
       "      <td>0.51077</td>\n",
       "      <td>0.670932</td>\n",
       "      <td>0.721581</td>\n",
       "      <td>0.784963</td>\n",
       "      <td>0.789205</td>\n",
       "      <td>0.789522</td>\n",
       "      <td>0.789724</td>\n",
       "      <td>0.78966</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.124255</td>\n",
       "      <td>0.375745</td>\n",
       "      <td>0.531376</td>\n",
       "      <td>0.671204</td>\n",
       "      <td>0.82868</td>\n",
       "      <td>0.842859</td>\n",
       "      <td>0.853304</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.515617</td>\n",
       "      <td>0.669877</td>\n",
       "      <td>0.63319</td>\n",
       "      <td>0.700725</td>\n",
       "      <td>0.699898</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>0.700059</td>\n",
       "      <td>0.699989</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Time</th>\n",
       "      <td>0.136425</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.181493</td>\n",
       "      <td>0.217716</td>\n",
       "      <td>0.35796</td>\n",
       "      <td>0.38343</td>\n",
       "      <td>0.398101</td>\n",
       "      <td>0.395138</td>\n",
       "      <td>0.406332</td>\n",
       "      <td>0.416245</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Time</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.00138</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0               1e-05    0.0001     0.001      0.01       0.1         1  \\\n",
       "Metrics                                                                   \n",
       "Accuracy      0.24682  0.738531   0.24682  0.680729  0.751456  0.829387   \n",
       "FBeta        0.145297  0.393289  0.145297  0.468519  0.618691  0.768487   \n",
       "Precision     0.12341  0.374755   0.12341  0.474825  0.642851  0.773008   \n",
       "Recall            0.5  0.490275       0.5  0.485514  0.590298  0.753706   \n",
       "Train Time  60.486689  0.200771  0.136941  0.111977   0.10925  0.106429   \n",
       "Test Time    0.002459     0.003  0.003397  0.003091  0.002464  0.002837   \n",
       "Accuracy      0.75318  0.704064   0.65381  0.666081  0.685796  0.751491   \n",
       "FBeta        0.396145  0.426279  0.426382  0.575154  0.512715  0.548683   \n",
       "Precision     0.37659  0.433052  0.425153  0.574578  0.519404  0.626969   \n",
       "Recall            0.5  0.478144  0.454594  0.583332  0.513522  0.538028   \n",
       "Train Time   0.117665  0.143671  0.162499  0.211548  0.238757  0.245574   \n",
       "Test Time     0.00131   0.00141  0.001485  0.001936  0.001225  0.001234   \n",
       "Accuracy     0.247165  0.752835  0.725399  0.786613  0.829973   0.88388   \n",
       "FBeta        0.145488  0.395993   0.39058  0.728338  0.780897  0.847419   \n",
       "Precision    0.123583  0.376417  0.372931  0.724556  0.775871  0.855873   \n",
       "Recall            0.5       0.5  0.481778  0.762269   0.82769  0.821062   \n",
       "Train Time  79.148934  6.674312  0.155501  0.122466  0.101879  0.103122   \n",
       "Test Time    0.002415  0.002356  0.002404   0.00249  0.002446  0.003006   \n",
       "Accuracy     0.247165  0.247165  0.641126  0.839693  0.816427  0.864095   \n",
       "FBeta        0.145488  0.145488  0.587626  0.791812  0.743486  0.836139   \n",
       "Precision    0.123583  0.123583  0.592415   0.90572  0.768231  0.910435   \n",
       "Recall            0.5       0.5  0.618763  0.677394  0.695053   0.72971   \n",
       "Train Time   0.126789  0.124429  0.135993  0.220526  0.331587  0.332329   \n",
       "Test Time    0.001182  0.001331  0.001253   0.00171  0.001631  0.001233   \n",
       "Accuracy     0.739737  0.459725  0.338124  0.767932  0.811533  0.822597   \n",
       "FBeta        0.436029  0.493494  0.373202   0.66752  0.743675  0.758238   \n",
       "Precision    0.499436  0.567409  0.467763  0.680959  0.748772  0.767386   \n",
       "Recall       0.499931  0.576663  0.470136   0.64067  0.727792   0.73274   \n",
       "Train Time   0.880714  1.666841  0.249369  0.102694  0.098618   0.10829   \n",
       "Test Time     0.00246  0.002596  0.005092  0.002375  0.002362  0.003235   \n",
       "Accuracy     0.248509  0.751491  0.710992  0.754834  0.809499   0.83859   \n",
       "FBeta        0.146233  0.395397   0.51077  0.670932  0.721581  0.784963   \n",
       "Precision    0.124255  0.375745  0.531376  0.671204   0.82868  0.842859   \n",
       "Recall            0.5       0.5  0.515617  0.669877   0.63319  0.700725   \n",
       "Train Time   0.136425  0.141401  0.181493  0.217716   0.35796   0.38343   \n",
       "Test Time    0.001442  0.001812  0.001422  0.002025   0.00138  0.001363   \n",
       "\n",
       "0                 10       100      1000     10000           Algorithm  \\\n",
       "Metrics                                                                  \n",
       "Accuracy    0.830524  0.830317  0.830421  0.830421          GaussianNB   \n",
       "FBeta        0.77131  0.771026  0.771171  0.771171          GaussianNB   \n",
       "Precision   0.772777  0.772491  0.772631  0.772631          GaussianNB   \n",
       "Recall      0.765868   0.76559  0.765752  0.765752          GaussianNB   \n",
       "Train Time  0.100889   0.10544  0.117998  0.106398          GaussianNB   \n",
       "Test Time   0.002372  0.002916  0.002707  0.004086          GaussianNB   \n",
       "Accuracy    0.749388   0.74925  0.749354  0.749285  LogisticRegression   \n",
       "FBeta       0.540137  0.539632   0.53967  0.539575  LogisticRegression   \n",
       "Precision   0.616819  0.616153  0.616556  0.616267  LogisticRegression   \n",
       "Recall       0.53405  0.533818   0.53384  0.533794  LogisticRegression   \n",
       "Train Time  0.319015  0.317679  0.292083  0.264385  LogisticRegression   \n",
       "Test Time   0.001334  0.001426  0.001248  0.001372  LogisticRegression   \n",
       "Accuracy    0.887085  0.887602  0.887568  0.887568          GaussianNB   \n",
       "FBeta       0.852113   0.85285  0.852805  0.852805          GaussianNB   \n",
       "Precision   0.860729   0.86145  0.861415  0.861415          GaussianNB   \n",
       "Recall      0.825251  0.826016  0.825946  0.825946          GaussianNB   \n",
       "Train Time  0.108585  0.101325  0.101835  0.101636          GaussianNB   \n",
       "Test Time   0.002764  0.002624  0.002413  0.002393          GaussianNB   \n",
       "Accuracy    0.872781  0.872368  0.870748  0.870748  LogisticRegression   \n",
       "FBeta       0.850023  0.850024  0.847464  0.847464  LogisticRegression   \n",
       "Precision   0.915081  0.917614  0.916677  0.916677  LogisticRegression   \n",
       "Recall      0.747515  0.745554  0.742277  0.742277  LogisticRegression   \n",
       "Train Time  0.441089  0.494465  0.506005  0.559494  LogisticRegression   \n",
       "Test Time   0.001169  0.001334   0.00124  0.001383  LogisticRegression   \n",
       "Accuracy    0.821804  0.821184  0.821149  0.821149          GaussianNB   \n",
       "FBeta       0.757287  0.756248    0.7562    0.7562          GaussianNB   \n",
       "Precision   0.765679  0.764972  0.764913  0.764913          GaussianNB   \n",
       "Recall      0.733419  0.731707  0.731684  0.731684          GaussianNB   \n",
       "Train Time  0.130749   0.09811  0.126721  0.120502          GaussianNB   \n",
       "Test Time   0.002405  0.002377  0.002909  0.002815          GaussianNB   \n",
       "Accuracy    0.840416  0.840554  0.840658  0.840623  LogisticRegression   \n",
       "FBeta       0.789205  0.789522  0.789724   0.78966  LogisticRegression   \n",
       "Precision   0.853304  0.854004  0.854202  0.854167  LogisticRegression   \n",
       "Recall      0.699898  0.699897  0.700059  0.699989  LogisticRegression   \n",
       "Train Time  0.398101  0.395138  0.406332  0.416245  LogisticRegression   \n",
       "Test Time   0.001339  0.001411  0.002447   0.00182  LogisticRegression   \n",
       "\n",
       "0          Data Type  \n",
       "Metrics               \n",
       "Accuracy         Raw  \n",
       "FBeta            Raw  \n",
       "Precision        Raw  \n",
       "Recall           Raw  \n",
       "Train Time       Raw  \n",
       "Test Time        Raw  \n",
       "Accuracy         Raw  \n",
       "FBeta            Raw  \n",
       "Precision        Raw  \n",
       "Recall           Raw  \n",
       "Train Time       Raw  \n",
       "Test Time        Raw  \n",
       "Accuracy         DWT  \n",
       "FBeta            DWT  \n",
       "Precision        DWT  \n",
       "Recall           DWT  \n",
       "Train Time       DWT  \n",
       "Test Time        DWT  \n",
       "Accuracy         DWT  \n",
       "FBeta            DWT  \n",
       "Precision        DWT  \n",
       "Recall           DWT  \n",
       "Train Time       DWT  \n",
       "Test Time        DWT  \n",
       "Accuracy          BW  \n",
       "FBeta             BW  \n",
       "Precision         BW  \n",
       "Recall            BW  \n",
       "Train Time        BW  \n",
       "Test Time         BW  \n",
       "Accuracy          BW  \n",
       "FBeta             BW  \n",
       "Precision         BW  \n",
       "Recall            BW  \n",
       "Train Time        BW  \n",
       "Test Time         BW  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.concat([raw,dwt,bw],axis=0)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c01754d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final.to_csv('Differential performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4284b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b532c38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0018b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9064f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99ccd9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
